"Modelo 2" = m2,
"Modelo 3" = m3,
"IV Costo" = m4a,
"IV Costo + Marca FE" = m4b,
"IV Costo + Marca*Tienda FE" = m4c,
"Hausman IV" = m5a,
"Hausman IV + Marca FE" = m5b,
"Hausman IV + Marca*Tienda FE" = m5c
)
modelsummary(models,
coef_rename = c("precio" = "Precio", "descuento" = "Descuento"),
gof_omit = ".*",
stars = TRUE,
output = "latex")
alpha_1 <- coef(m1)["precio"] #0,04 ??????
alpha_2 <- coef(m2)["precio"] #-0.1849338
alpha_3 <- coef(m3)["precio"] #-0.1860787
alpha_1
alpha_2
alpha_3
# Cargar paquetes
library(readxl)
library(dplyr)
library(antitrust)
library(ggplot2)
# Leer los datos
df <- read_excel("/Users/ninadicostanzopereira/Desktop/metodos/metodos_econometricos/TP2/input/datos1.xlsx") %>%
mutate(
marca_agrup = case_when(
marca %in% c(1, 2, 3)     ~ 1,
marca %in% c(4, 5, 6)     ~ 2,
marca %in% c(7, 8, 9)     ~ 3,
marca %in% c(10, 11)      ~ 4
)
) %>%
arrange(semana, tienda, marca_agrup) %>%
group_by(semana, tienda, marca_agrup) %>%
summarise(
ventas     = sum(ventas),
cantidad   = sum(cantidad),
precio     = sum(precio * cantidad) / sum(cantidad),      # promedio ponderado
descuento  = sum(descuento * cantidad) / sum(cantidad),   # promedio ponderado
costo      = sum(costo * cantidad) / sum(cantidad),       # promedio ponderado
.groups    = "drop"
) %>%
group_by(semana, tienda) %>%
mutate(
suma_ventas        = sum(ventas),
ventas_totales     = suma_ventas / 0.64,
share_marca        = ventas / ventas_totales,
lshare_marca       = log(share_marca),
lshare_outside_good = log(0.36),
delta_jt           = lshare_marca - lshare_outside_good
) %>%
ungroup()
# Filtrar mercado específico
mercado <- df %>%
filter(tienda == 9, semana == 10) %>%
arrange(marca_agrup) %>%
mutate(
Grupo     = marca_agrup,
precios   = precio,
costos    = costo,
shares    = share_marca
)
# Calcular márgenes observados
margenes <- (mercado$precios - mercado$costos) / mercado$precios
# Modelo Logit antitrust
modelo_antitrust <- logit(
prices    = mercado$precios,
shares    = mercado$shares,
margins   = margenes,
ownerPre  = factor(mercado$Grupo),
ownerPost = factor(c(1,1,1,2)),  # supongamos que Grupo 1,2,3 se fusionan
labels    = paste0("Grupo", mercado$Grupo)
)
# Ver resultados
summary(modelo_antitrust)
# Tabla con precios antes y después
resultados <- data.frame(
Grupo        = paste0("Grupo", mercado$Grupo),
Precio_Pre   = modelo_antitrust@pricePre,
Precio_Post  = modelo_antitrust@pricePost,
Delta_Precio = modelo_antitrust@pricePost - modelo_antitrust@pricePre
)
print(resultados)
# Gráfico
ggplot(resultados, aes(x = Grupo, y = Delta_Precio, fill = Grupo)) +
geom_col(show.legend = FALSE) +
labs(title = "Cambio en precios post-fusión", y = "Δ Precio", x = "Grupo") +
theme_minimal()
# Cargar paquetes
library(readxl)
library(dplyr)
library(antitrust)
library(ggplot2)
# Leer los datos
df <- read_excel("/Users/ninadicostanzopereira/Desktop/metodos/metodos_econometricos/TP2/input/datos1.xlsx") %>%
mutate(
marca_agrup = case_when(
marca %in% c(1, 2, 3)     ~ 1,
marca %in% c(4, 5, 6)     ~ 2,
marca %in% c(7, 8, 9)     ~ 3,
marca %in% c(10, 11)      ~ 4
)
) %>%
arrange(semana, tienda, marca_agrup) %>%
group_by(semana, tienda, marca_agrup) %>%
summarise(
ventas     = sum(ventas),
cantidad   = sum(cantidad),
precio     = sum(precio * cantidad) / sum(cantidad),      # promedio ponderado
descuento  = sum(descuento * cantidad) / sum(cantidad),   # promedio ponderado
costo      = sum(costo * cantidad) / sum(cantidad),       # promedio ponderado
.groups    = "drop"
) %>%
group_by(semana, tienda) %>%
mutate(
suma_ventas        = sum(ventas),
ventas_totales     = suma_ventas / 0.64,
share_marca        = ventas / ventas_totales,
lshare_marca       = log(share_marca),
lshare_outside_good = log(0.36),
delta_jt           = lshare_marca - lshare_outside_good
) %>%
ungroup()
# Filtrar mercado específico
mercado <- df %>%
filter(tienda == 9, semana == 10) %>%
arrange(marca_agrup) %>%
mutate(
Grupo     = marca_agrup,
precios   = precio,
costos    = costo,
shares    = share_marca
)
# Calcular márgenes observados
margenes <- (mercado$precios - mercado$costos) / mercado$precios
# Modelo Logit antitrust
modelo_antitrust <- logit(
prices    = mercado$precios,
shares    = mercado$shares,
margins   = margenes,
ownerPre  = factor(mercado$Grupo),
ownerPost = factor(c(1,1,1,2)),  # supongamos que Grupo 1,2,3 se fusionan
labels    = paste0("Grupo", mercado$Grupo)
)
# Ver resultados
summary(modelo_antitrust)
# Tabla con precios antes y después
resultados <- data.frame(
Grupo        = paste0("Grupo", mercado$Grupo),
Precio_Pre   = modelo_antitrust@pricePre,
Precio_Post  = modelo_antitrust@pricePost,
Delta_Precio = modelo_antitrust@pricePost - modelo_antitrust@pricePre
)
print(resultados)
# Gráfico
ggplot(resultados, aes(x = Grupo, y = Delta_Precio, fill = Grupo)) +
geom_col(show.legend = FALSE) +
labs(title = "Cambio en precios post-fusión", y = "Δ Precio", x = "Grupo") +
theme_minimal()
margenes
#-------------------------------------------------------------------------------
# Project:    Recolección de ofertas de subastas de ganado
# Name:       Nina
# Date:       ###
# Description: Scraping de ofertas individuales de OfertaGanadera.com
#-------------------------------------------------------------------------------
library(rvest)
library(dplyr)
library(stringr)
# URL del lote
url_lote <- "https://ofertaganadera.com/index.php/eventos/2da-gran-venta-anual-texel-y-hampshire-down-2021/product/231-lote-1-cabana-don-angel-10-rp-285"
# Leer el HTML de la página
pagina <- read_html(url_lote)
# Extraer datos del lote
lote <- pagina %>% html_nodes(".auction_details_table b")
lote
lote <- pagina %>% html_nodes(".auction_details_table b") %>% html_text()
lote
ofertas_nodes <- pagina %>%
html_nodes(.auction_details") %>% html_text()
ofertas_nodes
ofertas_nodes <- pagina %>%
html_nodes(".auction_details") %>% html_text()
ofertas_nodes
ofertas_nodes <- pagina %>%
html_nodes(".auction_details") %>% html_text()
ofertas_nodes
ofertas_nodes <- pagina %>% html_nodes(".auction_details") %>% html_text()
ofertas_nodes
precios <- ofertas_nodes[str_detect(ofertas_nodes, "ARS")]
fechas  <- ofertas_nodes[str_detect(ofertas_nodes, "^\\d{4}-\\d{2}-\\d{2}")]
precios
fechas
ofertas_df <- ofertas_tr %>%
map_df(~{
monto <- .x %>% html_node('td[data-title="amount"]') %>% html_text(trim = TRUE)
fecha <- .x %>% html_node('td[data-title="date"]') %>% html_text(trim = TRUE)
# Limpiar monto
monto <- str_replace_all(monto, "[\\s\\.ARS]", "")
monto <- as.numeric(monto)
# Convertir fecha
fecha <- as.POSIXct(fecha, format="%Y-%m-%d %H:%M")
data.frame(Monto = monto, Fecha = fecha)
})
ofertas_tr <- pagina %>%
html_nodes("div.auction_history_div table tbody tr.history_winning_bid")
ofertas_df <- ofertas_tr %>%
map_df(~{
monto <- .x %>% html_node('td[data-title="amount"]') %>% html_text(trim = TRUE)
fecha <- .x %>% html_node('td[data-title="date"]') %>% html_text(trim = TRUE)
# Limpiar monto
monto <- str_replace_all(monto, "[\\s\\.ARS]", "")
monto <- as.numeric(monto)
# Convertir fecha
fecha <- as.POSIXct(fecha, format="%Y-%m-%d %H:%M")
data.frame(Monto = monto, Fecha = fecha)
})
ofertas_tr
ofertas_tr <- pagina %>%
html_nodes("div.auction_history_div table tbody tr.history_winning_bid")
ofertas_df <- ofertas_tr %>%
map_df(~{
monto <- .x %>% html_node('td[data-title="amount"]') %>% html_text(trim = TRUE)
fecha <- .x %>% html_node('td[data-title="date"]') %>% html_text(trim = TRUE)
# Limpiar monto
monto <- str_replace_all(monto, "[\\s\\.ARS]", "")
monto <- as.numeric(monto)
# Convertir fecha
fecha <- as.POSIXct(fecha, format="%Y-%m-%d %H:%M")
data.frame(Monto = monto, Fecha = fecha)
})
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
library(lubridate)
library(sf)
library(fastDummies)
library(stargazer)
library(spdep)
# Seteo de directorio y abro la bases
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
terrenos <- read.csv("Terrenos-en-venta-2019.csv")
# Chequeo de NAs, vacíos o valores negativos
summary(terrenos)
colSums(is.na(terrenos))
colSums(terrenos == "", na.rm = TRUE)
colSums(terrenos < 0, na.rm = TRUE)
# Limpieza: elimino negativos y ceros
terrenos <- terrenos %>%
filter(M2TOTAL > 0, PRECIOUSD > 0)
# Calculo los log
terrenos <- terrenos %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
# Regresión base
reg_base <- lm(ln_preciousd ~ ln_m2total + BARRIO,
data = terrenos)
summary(reg_base)
# Exportar modelo a LaTeX
stargazer(reg_base, type = "latex",
title = "Modelo de Precios de Terrenos",
label = "MODELO",
dep.var.labels = "Log(Precio USD)",
covariate.labels = c("Log(M2)", levels(terrenos$barrio)[-1]),
omit.stat = c("f", "ser"),
no.space = TRUE)
# Descargo la base limpia con y sin residuos.
write_csv(terrenos, "terrenos_limpio.csv")
terrenos <- terrenos %>%
mutate(residuos_reg_base = residuals(reg_base))
write_csv(terrenos, "terrenos_limpio_res.csv")
# Abro el DF con las  variables que creamos en QGIS y dropeo de nuevo.
df <- read.csv("/Users/ninadicostanzopereira/Downloads/base_completa.csv") %>%
filter(M2TOTAL > 0, PRECIOUSD > 0) %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
base_final <- base_final %>%
mutate(residuos_reg2 = residuals(reg2))
base_final <- base %>%
left_join(
dplyr::select(terrenos_res, POLY_ID, residuos_reg_base),
by = "POLY_ID") %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
terrenos <- read.csv("Terrenos-en-venta-2019.csv")
# Chequeo de NAs, vacíos o valores negativos
summary(terrenos)
colSums(is.na(terrenos))
colSums(terrenos == "", na.rm = TRUE)
colSums(terrenos < 0, na.rm = TRUE)
# Limpieza: elimino negativos y ceros
terrenos <- terrenos %>%
filter(M2TOTAL > 0, PRECIOUSD > 0)
# Calculo los log
terrenos <- terrenos %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
# Regresión base
reg_base <- lm(ln_preciousd ~ ln_m2total + BARRIO,
data = terrenos)
summary(reg_base)
# Exportar modelo a LaTeX
stargazer(reg_base, type = "latex",
title = "Modelo de Precios de Terrenos",
label = "MODELO",
dep.var.labels = "Log(Precio USD)",
covariate.labels = c("Log(M2)", levels(terrenos$barrio)[-1]),
omit.stat = c("f", "ser"),
no.space = TRUE)
# Descargo la base limpia con y sin residuos.
write_csv(terrenos, "terrenos_limpio.csv")
terrenos <- terrenos %>%
mutate(residuos_reg_base = residuals(reg_base))
write_csv(terrenos, "terrenos_limpio_res.csv")
df <- read.csv("/Users/ninadicostanzopereira/Downloads/base_completa.csv") %>%
filter(M2TOTAL > 0, PRECIOUSD > 0) %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
base <- read.csv("/Users/ninadicostanzopereira/Desktop/Espacial/TP1/base_completa.csv")
terrenos_res <- read_csv("terrenos_limpio_res.csv")
intersect(names(base), names(terrenos_res))
base_final <- base %>%
left_join(
dplyr::select(terrenos_res, POLY_ID, residuos_reg_base),
by = "POLY_ID") %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
base_final <- base_final %>%
mutate(residuos_reg2 = residuals(reg2))
write_csv(base_final, "base_completa_con_residuos.csv")
#preguntar
reg2 <- lm(ln_preciousd ~ ln_m2total + BARRIO +
count_NUMPOINTS +
Matrix_distancia_f_Distance +
Matrix_.distancia_S_Distance +
Matriz_distancia_O_Distance,
data = df)
df <- read.csv("/Users/ninadicostanzopereira/Downloads/base_completa.csv") %>%
filter(M2TOTAL > 0, PRECIOUSD > 0) %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
# Calcular estadísticas descriptivas
stats <- df %>%
st_drop_geometry() %>%
summarise(across(c(count_NUMPOINTS,
Matrix_distancia_f_Distance,
Matrix_.distancia_S_Distance,
Matriz_distancia_O_Distance),
list(
media = ~ mean(.x, na.rm = TRUE),
mediana = ~ median(.x, na.rm = TRUE),
sd = ~ sd(.x, na.rm = TRUE),
minimo = ~ min(.x, na.rm = TRUE),
maximo = ~ max(.x, na.rm = TRUE)
),
.names = "{.col}_{.fn}"))
# Calcular correlaciones con la variable dependiente
correls <- df %>%
st_drop_geometry() %>%
summarise(across(c(count_NUMPOINTS,
Matrix_distancia_f_Distance,
Matrix_.distancia_S_Distance,
Matriz_distancia_O_Distance),
~ cor(.x, ln_preciousd, use = "complete.obs"),
.names = "{.col}_correl"))
tabla_final <- bind_cols(stats, correls)
print(tabla_final)
#preguntar
reg2 <- lm(ln_preciousd ~ ln_m2total + BARRIO +
count_NUMPOINTS +
Matrix_distancia_f_Distance +
Matrix_.distancia_S_Distance +
Matriz_distancia_O_Distance,
data = df)
summary(reg2)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
library(lubridate)
library(sf)
library(fastDummies)
library(stargazer)
library(spdep)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
terrenos <- read.csv("Terrenos-en-venta-2019.csv")
# Chequeo de NAs, vacíos o valores negativos
summary(terrenos)
colSums(is.na(terrenos))
colSums(terrenos == "", na.rm = TRUE)
colSums(terrenos < 0, na.rm = TRUE)
# Limpieza: elimino negativos y ceros
terrenos <- terrenos %>%
filter(M2TOTAL > 0, PRECIOUSD > 0)
# Calculo los log
terrenos <- terrenos %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
# Regresión base
reg_base <- lm(ln_preciousd ~ ln_m2total + BARRIO,
data = terrenos)
summary(reg_base)
# Exportar modelo a LaTeX
stargazer(reg_base, type = "latex",
title = "Modelo de Precios de Terrenos",
label = "MODELO",
dep.var.labels = "Log(Precio USD)",
covariate.labels = c("Log(M2)", levels(terrenos$barrio)[-1]),
omit.stat = c("f", "ser"),
no.space = TRUE)
# Descargo la base limpia con y sin residuos.
write_csv(terrenos, "terrenos_limpio.csv")
terrenos <- terrenos %>%
mutate(residuos_reg_base = residuals(reg_base))
write_csv(terrenos, "terrenos_limpio_res.csv")
df <- read.csv("/Users/ninadicostanzopereira/Downloads/base_completa.csv") %>%
filter(M2TOTAL > 0, PRECIOUSD > 0) %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
df <- read.csv("/Users/ninadicostanzopereira/Desktop/Espacial/TP1/base_completa.csv") %>%
filter(M2TOTAL > 0, PRECIOUSD > 0) %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
# Calcular estadísticas descriptivas
stats <- df %>%
st_drop_geometry() %>%
summarise(across(c(count_NUMPOINTS,
Matrix_distancia_f_Distance,
Matrix_.distancia_S_Distance,
Matriz_distancia_O_Distance),
list(
media = ~ mean(.x, na.rm = TRUE),
mediana = ~ median(.x, na.rm = TRUE),
sd = ~ sd(.x, na.rm = TRUE),
minimo = ~ min(.x, na.rm = TRUE),
maximo = ~ max(.x, na.rm = TRUE)
),
.names = "{.col}_{.fn}"))
# Calcular correlaciones con la variable dependiente
correls <- df %>%
st_drop_geometry() %>%
summarise(across(c(count_NUMPOINTS,
Matrix_distancia_f_Distance,
Matrix_.distancia_S_Distance,
Matriz_distancia_O_Distance),
~ cor(.x, ln_preciousd, use = "complete.obs"),
.names = "{.col}_correl"))
tabla_final <- bind_cols(stats, correls)
print(tabla_final)
#preguntar
reg2 <- lm(ln_preciousd ~ ln_m2total + BARRIO +
count_NUMPOINTS +
Matrix_distancia_f_Distance +
Matrix_.distancia_S_Distance +
Matriz_distancia_O_Distance,
data = df)
summary(reg2)
stargazer(reg, type = "latex",
title = "Modelo de Precios de Terrenos",
label = "MODELO",
dep.var.labels = "Log(Precio USD)",
covariate.labels = c("Log(M2)", levels(terrenos$barrio)[-1]),
omit.stat = c("f", "ser"),
no.space = TRUE)
base <- read.csv("/Users/ninadicostanzopereira/Desktop/Espacial/TP1/base_completa.csv")
stargazer(reg2, type = "latex",
title = "Modelo de Precios de Terrenos",
label = "MODELO",
dep.var.labels = "Log(Precio USD)",
covariate.labels = c("Log(M2)", levels(terrenos$barrio)[-1]),
omit.stat = c("f", "ser"),
no.space = TRUE)
base <- read.csv("/Users/ninadicostanzopereira/Desktop/Espacial/TP1/base_completa.csv")
terrenos_res <- read_csv("terrenos_limpio_res.csv")
intersect(names(base), names(terrenos_res))
base_final <- base %>%
left_join(
dplyr::select(terrenos_res, POLY_ID, residuos_reg_base),
by = "POLY_ID") %>%
mutate(
ln_preciousd = log(PRECIOUSD),
ln_m2total   = log(M2TOTAL)
)
base_final <- base_final %>%
mutate(residuos_reg2 = residuals(reg2))
